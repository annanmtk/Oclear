{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MNIST'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f4bcd448de15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'MNIST'"
     ]
    }
   ],
   "source": [
    "import MNIST\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Global Variables\n",
    "\n",
    "training_size = 3000\n",
    "validation_size = 1000\n",
    "testing_size = 1000\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Predicts the instances labels using top k neighbours\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def predict(neighbours, k):\n",
    "    top_k = [Counter(x[:k]) for x in neighbours]\n",
    "    predicted_labels = [x.most_common(1)[0][0] for x in top_k]\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Finds the optimal value of k using cross validation.\n",
    "The value of k with minimum error is the optimal one\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def find_k(neighbours, real_validation_labels, similarity_measure):\n",
    "    k_values = []\n",
    "    error_values = []\n",
    "\n",
    "    real_validation_labels = list(real_validation_labels)\n",
    "\n",
    "    \"\"\"\n",
    "    Its a convention to start from k = 1 to k = sqrt(N) where N is the size of training data\n",
    "    \"\"\"\n",
    "    for k in range(math.ceil(math.sqrt(training_size))):\n",
    "        k += 1\n",
    "\n",
    "        predicted_labels = predict(neighbours, k)\n",
    "\n",
    "        # check accuracy\n",
    "        acc = accuracy_score(real_validation_labels, predicted_labels)\n",
    "\n",
    "        k_values.append(k)\n",
    "        error_values.append(1 - acc)\n",
    "\n",
    "    if similarity_measure == 1:\n",
    "        s = \"Cosine Similarity\"\n",
    "    else:\n",
    "        s = \"Euclidean Distance\"\n",
    "\n",
    "    k = k_values[np.argmin(error_values)]\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Plotting the Validation Error Curve \"\"\"\n",
    "\n",
    "    plt.ylabel('Validation Error', fontsize=14)\n",
    "    plt.xlabel('K', fontsize=14)\n",
    "    plt.title(\"Validation Error Curve using %s\" % s, fontsize=16, color='green')\n",
    "    plt.plot(k_values, error_values, 'bo--')\n",
    "    figure = plt.gcf()  # get current figure\n",
    "    figure.set_size_inches(13, 7)\n",
    "\n",
    "    plt.savefig(\"Validation Error Curve using %s.png\" % s, dpi=300)\n",
    "    plt.clf()\n",
    "\n",
    "    \"\"\"\n",
    "    The value of K which gave minimum validation error is the optimal value of k\n",
    "    \"\"\"\n",
    "    return k_values[np.argmin(error_values)]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def knn(train_images, test_images, train_labels, similarity_measure):\n",
    "    if similarity_measure == 1:\n",
    "        # compute cosine similarity\n",
    "        v = [[np.dot(x, y)/(np.linalg.norm(x) * np.linalg.norm(y)) for y in train_images] for x in test_images]\n",
    "        # v = cosine_similarity(test_images, train_images)\n",
    "        r = True\n",
    "    else:\n",
    "        # compute euclidean distance\n",
    "        v = [[np.sum((x - y) ** 2) for y in train_images] for x in test_images]\n",
    "        r = False\n",
    "\n",
    "    # append labels\n",
    "    v = [[(x[i], train_labels[i]) for i in range(len(x))] for x in v]\n",
    "\n",
    "    # sort in descending order\n",
    "    [x.sort(key=lambda y: y[0], reverse=r) for x in v]\n",
    "\n",
    "    # get all neighbours\n",
    "    neighbours = [[n for similarity, n in x] for x in v]\n",
    "\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Note: This is an experiment in which first the optimal value of K is determined using the\n",
    "      cross validation technique and then its used to classify test images. This experiment\n",
    "      is run twice. Once for Cosine Similarity and once for Euclidean Distance.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_experiment(train_images, train_labels, test_images, test_labels, validation_images, validation_labels,\n",
    "                   similarity_measure):\n",
    "    \"\"\"\n",
    "    First finding the optimal value of K using validation images\n",
    "    and then using it to classify test images\n",
    "    \"\"\"\n",
    "\n",
    "    if similarity_measure == 1:\n",
    "        s = \"Cosine Similarity\"\n",
    "    else:\n",
    "        s = \"Euclidean Distance\"\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Running Experiment using %s\" % s)\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "    print(\"Finding Optimal Value of K ...\")\n",
    "    neighbours_labels = knn(train_images, validation_images, train_labels, similarity_measure)\n",
    "    k = find_k(neighbours_labels, validation_labels, similarity_measure)\n",
    "\n",
    "    print(\"Optimal Value of K using Cross Validation is: %d\" % k)\n",
    "    print(\"Classifying Test Images ...\")\n",
    "\n",
    "    start_time = time.clock()\n",
    "\n",
    "    neighbours_labels = knn(train_images, test_images, train_labels, similarity_measure)\n",
    "    predicted_labels = predict(neighbours_labels, k)\n",
    "\n",
    "    print(\"Prediction Time: %.2f seconds\" % (time.clock() - start_time))\n",
    "\n",
    "    print(\"Test Images Classified!\")\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels) * 100\n",
    "\n",
    "    print(\"KNN with k = %d\" % k)\n",
    "    print(\"Accuracy: %f\" % accuracy, \"%\")\n",
    "    print(\"---------------------\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    data = MNIST('samples')\n",
    "\n",
    "    train_images, train_labels = data.load_training()\n",
    "    test_images, test_labels = data.load_testing()\n",
    "\n",
    "    validation_images = np.array(train_images[training_size:training_size + validation_size])\n",
    "    validation_labels = np.array(train_labels[training_size:training_size + validation_size])\n",
    "\n",
    "    train_images = np.array(train_images[:training_size])\n",
    "    train_labels = np.array(train_labels[:training_size])\n",
    "\n",
    "    test_images = np.array(test_images[:testing_size])\n",
    "    test_labels = np.array(test_labels[:testing_size])\n",
    "\n",
    "    \"\"\"Rescaling Data\"\"\"\n",
    "    train_images = train_images/255\n",
    "    test_images = test_images/255\n",
    "    validation_images = validation_images/255\n",
    "\n",
    "    \"\"\" run knn with cosine similarity as similarity measure \"\"\"\n",
    "    run_experiment(train_images, train_labels, test_images, test_labels, validation_images, validation_labels, 1)\n",
    "\n",
    "    \"\"\" run knn with euclidean distance as similarity measure \"\"\"\n",
    "    run_experiment(train_images, train_labels, test_images, test_labels, validation_images, validation_labels, 2)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "# get things rolling\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
